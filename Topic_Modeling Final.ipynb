{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bce2bb89",
      "metadata": {
        "id": "bce2bb89"
      },
      "source": [
        "# ADS 509 Assignment 5.1: Topic Modeling\n",
        "\n",
        "This notebook holds Assignment 5.1 for Module 5 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
        "\n",
        "In this assignment you will work with a categorical corpus that accompanies `nltk`. You will build the three types of topic models described in Chapter 8 of _Blueprints for Text Analytics using Python_: NMF, LSA, and LDA. You will compare these models to the true categories. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d87e2c06",
      "metadata": {
        "id": "d87e2c06"
      },
      "source": [
        "## General Assignment Instructions\n",
        "\n",
        "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
        "\n",
        "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
        "\n",
        "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
        "\n",
        "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#note: this needs to be ran when starting the notebook each time.\n",
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "id": "jAEFRHyNQTrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d41a59-3346-44aa-efcc-07c8182a0711"
      },
      "id": "jAEFRHyNQTrF",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyLDAvis\n",
            "  Using cached pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.21.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.7.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (2.8.4)\n",
            "Collecting funcy\n",
            "  Using cached funcy-1.18-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim->pyLDAvis) (6.3.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n",
            "Building wheels for collected packages: pyLDAvis, sklearn\n",
            "  Building wheel for pyLDAvis (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136898 sha256=5118dc4c0b4f36fef295e48f260e02b8bc150758182b33ddc03e6b99bfdebbcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/61/ec/9dbe9efc3acf9c4e37ba70fbbcc3f3a0ebd121060aa593181a\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=9c0338c206825516dc1cb70d9f27ce33ed91267794eb01663b21064d09b5dc22\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built pyLDAvis sklearn\n",
            "Installing collected packages: sklearn, funcy, pyLDAvis\n",
            "Successfully installed funcy-1.18 pyLDAvis-3.3.1 sklearn-0.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a85bce08",
      "metadata": {
        "id": "a85bce08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe3b228-8b45-44d4-9950-cc32eec628b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "/usr/local/lib/python3.8/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.8/dist-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
            "  from collections import Mapping\n"
          ]
        }
      ],
      "source": [
        "# These libraries may be useful to you\n",
        "import nltk \n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
        "\n",
        "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.sklearn\n",
        "import pyLDAvis.gensim_models\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a218df60",
      "metadata": {
        "id": "a218df60"
      },
      "outputs": [],
      "source": [
        "# add any additional libaries you need here\n",
        "from nltk.corpus import brown as brown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "494de237",
      "metadata": {
        "id": "494de237"
      },
      "outputs": [],
      "source": [
        "# This function comes from the BTAP repo.\n",
        "\n",
        "def display_topics(model, features, no_top_words=5):\n",
        "    for topic, words in enumerate(model.components_):\n",
        "        total = words.sum()\n",
        "        largest = words.argsort()[::-1] # invert sort order\n",
        "        print(\"\\nTopic %02d\" % topic)\n",
        "        for i in range(0, no_top_words):\n",
        "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a30a901c",
      "metadata": {
        "id": "a30a901c"
      },
      "source": [
        "## Getting to Know the Brown Corpus\n",
        "\n",
        "Let's spend a bit of time getting to know what's in the Brown corpus, our NLTK example of an \"overlapping\" corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "457c59ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "457c59ed",
        "outputId": "349cf9ea-cc98-4784-f976-d40102c14a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For adventure we have 29 articles.\n",
            "For belles_lettres we have 75 articles.\n",
            "For editorial we have 27 articles.\n",
            "For fiction we have 29 articles.\n",
            "For government we have 30 articles.\n",
            "For hobbies we have 36 articles.\n",
            "For humor we have 9 articles.\n",
            "For learned we have 80 articles.\n",
            "For lore we have 48 articles.\n",
            "For mystery we have 24 articles.\n",
            "For news we have 44 articles.\n",
            "For religion we have 17 articles.\n",
            "For reviews we have 17 articles.\n",
            "For romance we have 29 articles.\n",
            "For science_fiction we have 6 articles.\n"
          ]
        }
      ],
      "source": [
        "# categories of articles in Brown corpus\n",
        "all_brown_cat = []\n",
        "for category in brown.categories() :\n",
        "  all_brown_cat.append(category)\n",
        "  print(f\"For {category} we have {len(brown.fileids(categories=category))} articles.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23fb133c",
      "metadata": {
        "id": "23fb133c"
      },
      "source": [
        "Let's create a dataframe of the articles in of hobbies, editorial, government, news, and romance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "18f50b9d",
      "metadata": {
        "id": "18f50b9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b997b98d-8d4c-4932-f5f0-021d756f516c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(166, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "categories = ['editorial','government','news','romance','hobbies'] \n",
        "\n",
        "category_list = []\n",
        "file_ids = []\n",
        "texts = []\n",
        "\n",
        "for category in categories : \n",
        "    for file_id in brown.fileids(categories=category) :\n",
        "        \n",
        "        # build some lists for a dataframe\n",
        "        category_list.append(category)\n",
        "        file_ids.append(file_id)\n",
        "        \n",
        "        text = brown.words(fileids=file_id)\n",
        "        texts.append(\" \".join(text))\n",
        "\n",
        "        \n",
        "        \n",
        "df = pd.DataFrame()\n",
        "df['category'] = category_list\n",
        "df['id'] = file_ids\n",
        "df['text'] = texts \n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "586f47de",
      "metadata": {
        "id": "586f47de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "46d07683-8242-4e4b-d658-1441735bb977"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    category    id                                               text  \\\n",
              "0  editorial  cb01  Assembly session brought much good The General...   \n",
              "1  editorial  cb02  Must Berlin remain divided ? ? The inference h...   \n",
              "2  editorial  cb03  A good man departs . Goodby , Mr. Sam . Sam Ra...   \n",
              "3  editorial  cb04  A shock wave from Africa Word of Dag Hammarskj...   \n",
              "4  editorial  cb05  Help when needed If the Dominican Republic ach...   \n",
              "\n",
              "   char_len  word_len  \n",
              "0     12659      2200  \n",
              "1     12544      2234  \n",
              "2     11871      2244  \n",
              "3     12284      2230  \n",
              "4     12479      2241  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a19afde-a87d-4ebb-81a4-4af4b051a5da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>char_len</th>\n",
              "      <th>word_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>editorial</td>\n",
              "      <td>cb01</td>\n",
              "      <td>Assembly session brought much good The General...</td>\n",
              "      <td>12659</td>\n",
              "      <td>2200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>editorial</td>\n",
              "      <td>cb02</td>\n",
              "      <td>Must Berlin remain divided ? ? The inference h...</td>\n",
              "      <td>12544</td>\n",
              "      <td>2234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>editorial</td>\n",
              "      <td>cb03</td>\n",
              "      <td>A good man departs . Goodby , Mr. Sam . Sam Ra...</td>\n",
              "      <td>11871</td>\n",
              "      <td>2244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>editorial</td>\n",
              "      <td>cb04</td>\n",
              "      <td>A shock wave from Africa Word of Dag Hammarskj...</td>\n",
              "      <td>12284</td>\n",
              "      <td>2230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>editorial</td>\n",
              "      <td>cb05</td>\n",
              "      <td>Help when needed If the Dominican Republic ach...</td>\n",
              "      <td>12479</td>\n",
              "      <td>2241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a19afde-a87d-4ebb-81a4-4af4b051a5da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a19afde-a87d-4ebb-81a4-4af4b051a5da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a19afde-a87d-4ebb-81a4-4af4b051a5da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Let's add some helpful columns on the df\n",
        "df['char_len'] = df['text'].apply(len)\n",
        "df['word_len'] = df['text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "#view contents of the df\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "2128fd2d",
      "metadata": {
        "id": "2128fd2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "e17a96cb-db6d-48aa-8cee-87c6f2e97d89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbe904d4460>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "df.groupby('category').agg({'word_len': 'mean'}).plot.bar(figsize=(10,6))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "554ffeb5",
      "metadata": {
        "id": "554ffeb5"
      },
      "source": [
        "Now do our TF-IDF and Count vectorizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "21a7d247",
      "metadata": {
        "id": "21a7d247",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4601c7d6-9adb-4c74-b83b-e9c68b65bfa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(166, 4941)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "count_text_vectorizer = CountVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
        "count_text_vectors = count_text_vectorizer.fit_transform(df[\"text\"])\n",
        "count_text_vectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "875deba9",
      "metadata": {
        "id": "875deba9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc996d20-1609-4426-851b-652c2f4c6c9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(166, 4941)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "tfidf_text_vectorizer = TfidfVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
        "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(df['text'])\n",
        "tfidf_text_vectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_text_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLEz-9s8HGyx",
        "outputId": "9df0f7eb-9554-4c19-97ed-79b55a27c090"
      },
      "id": "oLEz-9s8HGyx",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<166x4941 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 72541 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_text_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxzSzYeiHOYN",
        "outputId": "12e3f987-df2f-45ba-a1ab-9648ef03bac9"
      },
      "id": "vxzSzYeiHOYN",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<166x4941 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 72541 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lDm4C0H3Uhv1"
      },
      "id": "lDm4C0H3Uhv1"
    },
    {
      "cell_type": "markdown",
      "id": "a1062b21",
      "metadata": {
        "id": "a1062b21"
      },
      "source": [
        "Q: What do the two data frames `count_text_vectors` and `tfidf_text_vectors` hold? \n",
        "\n",
        "A:\n",
        "* `count_text_vectors`:  This is a sparse matrix where each row is a document, and each column in a word, where the the frequency of each word in each document is counted. Stop words are removed from this matrix. \n",
        "\n",
        "* `tfidf_text_vectors`:  This is a term frequency-inverse document frequency of each word in each document. This value is a a weight that is assigned to each word that takes into account both the frequency that the word appears within the text and within the entirety of the corpus. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f77c3f94",
      "metadata": {
        "id": "f77c3f94"
      },
      "source": [
        "## Fitting a Non-Negative Matrix Factorization Model\n",
        "\n",
        "In this section the code to fit a five-topic NMF model has already been written. This code comes directly from the [BTAP repo](https://github.com/blueprints-for-text-analytics-python/blueprints-text), which will help you tremendously in the coming sections. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "d28745a3",
      "metadata": {
        "id": "d28745a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b111447-5c24-4fee-8382-44226faf350d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "nmf_text_model = NMF(n_components=5, random_state=314)\n",
        "W_text_matrix = nmf_text_model.fit_transform(tfidf_text_vectors)\n",
        "H_text_matrix = nmf_text_model.components_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "a67185e7",
      "metadata": {
        "id": "a67185e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de4f2a08-7bfa-42bd-b717-05763ec6df3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic 00\n",
            "  mr (0.51)\n",
            "  president (0.45)\n",
            "  kennedy (0.43)\n",
            "  united (0.42)\n",
            "  khrushchev (0.40)\n",
            "\n",
            "Topic 01\n",
            "  said (0.88)\n",
            "  didn (0.46)\n",
            "  ll (0.45)\n",
            "  thought (0.42)\n",
            "  man (0.37)\n",
            "\n",
            "Topic 02\n",
            "  state (0.40)\n",
            "  development (0.36)\n",
            "  tax (0.33)\n",
            "  sales (0.30)\n",
            "  program (0.25)\n",
            "\n",
            "Topic 03\n",
            "  mrs (2.61)\n",
            "  mr (0.78)\n",
            "  said (0.64)\n",
            "  miss (0.52)\n",
            "  car (0.51)\n",
            "\n",
            "Topic 04\n",
            "  game (1.01)\n",
            "  league (0.74)\n",
            "  ball (0.72)\n",
            "  baseball (0.71)\n",
            "  team (0.66)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "#display the topics produced by NMF model\n",
        "display_topics(nmf_text_model, tfidf_text_vectorizer.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fee51e9b",
      "metadata": {
        "id": "fee51e9b"
      },
      "source": [
        "Now some work for you to do. Compare the NMF factorization to the original categories from the Brown Corpus.\n",
        "\n",
        "We are interested in the extent to which our NMF factorization agrees or disagrees with the original categories in the corpus. For each topic in your NMF model, tally the Brown categories and interpret the results. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "7c8c8eb0",
      "metadata": {
        "id": "7c8c8eb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc66873-6a52-4f43-86bc-c7c3b5f8185e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['editorial' 'government' 'news' 'romance' 'hobbies']\n"
          ]
        }
      ],
      "source": [
        "#show the original brown categories the data frame\n",
        "print(df.category.unique())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a dictionary to map topics to categories\n",
        "topic_to_category = {}\n",
        "\n",
        "#iterate over the topics in the NMF model\n",
        "for topic_id, topic in enumerate(W_text_matrix.T):\n",
        "    most_relevant_docs = np.argsort(topic)[::-1][:5]\n",
        "    categories = [df.iloc[doc_idx]['category'] for doc_idx in most_relevant_docs]\n",
        "    topic_to_category[topic_id] = Counter(categories)\n",
        "\n",
        "#print the topics and the categories they are associated with\n",
        "for topic_id, category_counts in topic_to_category.items():\n",
        "    print(\"Topic %d:\" % topic_id)\n",
        "    for category, count in category_counts.items():\n",
        "        print(\"  %s: %d\" % (category, count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw5c8dFXM68p",
        "outputId": "ce9a36ff-9d6f-4e02-9918-588ecf6b64cb"
      },
      "id": "pw5c8dFXM68p",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "  editorial: 2\n",
            "  news: 3\n",
            "Topic 1:\n",
            "  romance: 5\n",
            "Topic 2:\n",
            "  government: 4\n",
            "  news: 1\n",
            "Topic 3:\n",
            "  news: 5\n",
            "Topic 4:\n",
            "  news: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8d4e2bc",
      "metadata": {
        "id": "f8d4e2bc"
      },
      "source": [
        "Q: How does your five-topic NMF model compare to the original Brown categories? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overview of Comparison of NMF model to original Brown categories:\n",
        "\n",
        "* Topic 00 topics produced by the NMF model include:  mr, president, kennedy, united, and hrushchev. Comparing back to the Brown corpus, the categories suggest editorial and news. \n",
        "\n",
        "* Topic 01 topics produced by the NMF model include:  said, didn, ll, thought man. Comparing back to the Brown corpus, the categories suggest romance. \n",
        "\n",
        "* Topic 02 topics produced by the NMF model include:  state, development, sales, tax, program. Comparing back to the Brown corpus, the categories suggest government and news. \n",
        "\n",
        "* Topic 03 topics produced by the NMF model include:  mrs, mr, said, miss, car. Comoparing back to the Bronw corpus, the categories suggest news. \n",
        "\n",
        "* Topic 04 topics produced by the NMF model include:  game, league, ball, baseball, team. Comparing back to the Brown coprus, the categories suggest news. \n",
        "\n",
        "### Summation:\n",
        "Topics 00 and 02 appear to clearly relate to an editorial and a government context. Topics 01, 03, and 04 are less apparent, as without knowledge of what the categories \"should\" be, I would likely not associate the topics from the NMF model to the categories within the Brown corpus. This is especially the case for Topic 01, where said, didn, ll, thought and man (generally incoherent results) are related to Romance, and Topic 04 being related to News, whereas I likely would have placed that into a baseball/hobby category, unless I knew the corpus from which I was drawing the data from was \"News\" but from a sports perspective, or the time range associtaed with the news was during the World Series. "
      ],
      "metadata": {
        "id": "jCfNkGe7MR7M"
      },
      "id": "jCfNkGe7MR7M"
    },
    {
      "cell_type": "markdown",
      "id": "82e37cb5",
      "metadata": {
        "id": "82e37cb5"
      },
      "source": [
        "## Fitting an LSA Model\n",
        "\n",
        "In this section, follow the example from the repository and fit an LSA model (called a \"TruncatedSVD\" in `sklearn`). Again fit a five-topic model and compare it to the actual categories in the Brown corpus. Use the TF-IDF vectors for your fit, as above. \n",
        "\n",
        "To be explicit, we are once again interested in the extent to which this LSA factorization agrees or disagrees with the original categories in the corpus. For each topic in your model, tally the Brown categories and interpret the results. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "00b53d3d",
      "metadata": {
        "id": "00b53d3d"
      },
      "outputs": [],
      "source": [
        "#create a topic model with Latent Semantic Analysis (LSA), SVD(singular value decomposition)\n",
        "svd_text_model = TruncatedSVD(n_components = 5, random_state=314)\n",
        "W_svd_text_matrix = svd_text_model.fit_transform(tfidf_text_vectors)\n",
        "H_svd_text_matrix = svd_text_model.components_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#display the feature names within the SVD\n",
        "display_topics(svd_text_model, tfidf_text_vectorizer.get_feature_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqgXX2OIParZ",
        "outputId": "08329f1a-d151-48d6-9165-9d979def58d7"
      },
      "id": "gqgXX2OIParZ",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic 00\n",
            "  said (0.44)\n",
            "  mr (0.25)\n",
            "  mrs (0.22)\n",
            "  state (0.20)\n",
            "  man (0.17)\n",
            "\n",
            "Topic 01\n",
            "  said (3.89)\n",
            "  ll (2.73)\n",
            "  didn (2.63)\n",
            "  thought (2.20)\n",
            "  got (1.97)\n",
            "\n",
            "Topic 02\n",
            "  mrs (3.12)\n",
            "  mr (1.70)\n",
            "  said (1.06)\n",
            "  kennedy (0.82)\n",
            "  khrushchev (0.77)\n",
            "\n",
            "Topic 03\n",
            "  mrs (29.45)\n",
            "  club (6.53)\n",
            "  game (6.12)\n",
            "  jr (5.60)\n",
            "  university (5.20)\n",
            "\n",
            "Topic 04\n",
            "  game (4.54)\n",
            "  league (3.27)\n",
            "  baseball (3.22)\n",
            "  ball (3.10)\n",
            "  team (2.94)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a dictionary to map topics to categories\n",
        "topic_to_category = {}\n",
        "\n",
        "#iterate over the topics in the SVD model\n",
        "for topic_idx, topic in enumerate(W_svd_text_matrix.T):\n",
        "    most_relevant_docs = np.argsort(topic)[::-1][:5]\n",
        "    categories = [df.iloc[doc_idx]['category'] for doc_idx in most_relevant_docs]\n",
        "    topic_to_category[topic_idx] = Counter(categories)\n",
        "\n",
        "#print the topics and the categories they are associated with\n",
        "for topic_idx, category_counts in topic_to_category.items():\n",
        "    print(\"Topic %d:\" % topic_idx)\n",
        "    for category, count in category_counts.items():\n",
        "        print(\"  %s: %d\" % (category, count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMH5OEHeevTy",
        "outputId": "86b52ca8-76ad-424e-c007-042fc5e75657"
      },
      "id": "dMH5OEHeevTy",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "  news: 4\n",
            "  romance: 1\n",
            "Topic 1:\n",
            "  romance: 5\n",
            "Topic 2:\n",
            "  news: 5\n",
            "Topic 3:\n",
            "  news: 5\n",
            "Topic 4:\n",
            "  news: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d94d56f",
      "metadata": {
        "id": "4d94d56f"
      },
      "source": [
        "Q: How does your five-topic LSA model compare to the original Brown categories? \n",
        "\n",
        "* Topic 00 topics produced by the SVD model include:  said, mr, mrs, state man. Comparing back to the Brown corpus, the categories suggest news and romance. \n",
        "\n",
        "* Topic 01 topics produced by the SVD model include:  said, didn, ll, thought got. Comparing back to the Brown corpus, the categories suggest romance. \n",
        "\n",
        "* Topic 02 topics produced by the SVD model include:  mrs, mr, said, kennedy, khrushchev. Comparing back to the Brown corpus, the categories suggest news. \n",
        "\n",
        "* Topic 03 topics produced by the SVD model include:  mrs, club, game, jr, university. Comparing back to the Brown corpus, the categories suggest news. \n",
        "\n",
        "* Topic 04 topics produced by the SVD model include:  game, league, baseball, ball, team. Comparing back to the Brown coprus, the categories suggest news. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea8b280a",
      "metadata": {
        "id": "ea8b280a"
      },
      "source": [
        "Q: What is your interpretation of the display topics output? \n",
        "\n",
        "A: Immediately, it is apparent that the news category in the Brown corpus is overwhelmingly abundent when comparing back to the SVD model. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4ab4d29",
      "metadata": {
        "id": "b4ab4d29"
      },
      "source": [
        "## Fitting an LDA Model\n",
        "\n",
        "Finally, fit a five-topic LDA model using the count vectors (`count_text_vectors` from above). Display the results using `pyLDAvis.display` and describe what you learn from that visualization. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "802cb8ff",
      "metadata": {
        "id": "802cb8ff"
      },
      "outputs": [],
      "source": [
        "#Fit your LDA model here\n",
        "lda_text_model = LatentDirichletAllocation(n_components=5, random_state=314)\n",
        "W_lda_text_matrix = lda_text_model.fit_transform(count_text_vectors)\n",
        "H_lda_text_matrix = lda_text_model.components_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "ab18adf5",
      "metadata": {
        "id": "ab18adf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28d72db-79cf-4c35-f54f-3477f4e4c755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic 00\n",
            "  said (1.05)\n",
            "  mrs (0.82)\n",
            "  little (0.56)\n",
            "  good (0.51)\n",
            "  way (0.50)\n",
            "\n",
            "Topic 01\n",
            "  state (0.67)\n",
            "  development (0.63)\n",
            "  000 (0.57)\n",
            "  program (0.48)\n",
            "  business (0.44)\n",
            "\n",
            "Topic 02\n",
            "  said (1.18)\n",
            "  mr (0.72)\n",
            "  president (0.51)\n",
            "  city (0.43)\n",
            "  state (0.37)\n",
            "\n",
            "Topic 03\n",
            "  feed (0.55)\n",
            "  college (0.54)\n",
            "  general (0.44)\n",
            "  university (0.43)\n",
            "  work (0.37)\n",
            "\n",
            "Topic 04\n",
            "  states (1.14)\n",
            "  state (1.02)\n",
            "  united (0.84)\n",
            "  shall (0.66)\n",
            "  government (0.61)\n"
          ]
        }
      ],
      "source": [
        "#Call `display_topics` on your fitted model here\n",
        "display_topics(lda_text_model, tfidf_text_vectorizer.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2c67876",
      "metadata": {
        "id": "f2c67876"
      },
      "source": [
        "Q: What inference do you draw from the displayed topics for your LDA model? \n",
        "\n",
        "What immediatlely differentiates the LDA model from the others, is that the words it is producing are more unique relative to the NMF and SVD models. There is less overlap of the same words (mr, mrs especially) and the words, when looked at holistically by topic, make more sense intuitively as a group. Where a few of the topics produced in both the NMF and SVD models are generally incoherient, the LDA model does not have this same issue, and all 5 of the topics produced could be used as some type of category. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: Repeat the tallying of Brown categories within your topics. How does your five-topic LDA model compare to the original Brown categories? "
      ],
      "metadata": {
        "id": "EW_6J-g-Z1if"
      },
      "id": "EW_6J-g-Z1if"
    },
    {
      "cell_type": "code",
      "source": [
        "#create a dictionary to map topics to categories\n",
        "topic_to_category = {}\n",
        "\n",
        "#iterate over the topics in the NMF model\n",
        "for topic_idx, topic in enumerate(W_lda_text_matrix.T):\n",
        "    most_relevant_docs = np.argsort(topic)[::-1][:5]\n",
        "    categories = [df.iloc[doc_idx]['category'] for doc_idx in most_relevant_docs]\n",
        "    topic_to_category[topic_idx] = Counter(categories)\n",
        "\n",
        "#print the topics and the categories they are associated with\n",
        "for topic_idx, category_counts in topic_to_category.items():\n",
        "    print(\"Topic %d:\" % topic_idx)\n",
        "    for category, count in category_counts.items():\n",
        "        print(\"  %s: %d\" % (category, count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvZFyltCRxhI",
        "outputId": "a4fa9039-335b-46d1-9a49-c377f925b344"
      },
      "id": "qvZFyltCRxhI",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "  hobbies: 1\n",
            "  romance: 4\n",
            "Topic 1:\n",
            "  government: 5\n",
            "Topic 2:\n",
            "  news: 3\n",
            "  government: 1\n",
            "  editorial: 1\n",
            "Topic 3:\n",
            "  hobbies: 4\n",
            "  news: 1\n",
            "Topic 4:\n",
            "  government: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The LDA model, while still having some topics that have multiple categories from the Brown corpus listed, does a better job at finding the uniquness contained within the original Brown corpus compaired to the NMF and SVD models. "
      ],
      "metadata": {
        "id": "ShYZTePlddTd"
      },
      "id": "ShYZTePlddTd"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "6aae75ca",
      "metadata": {
        "id": "6aae75ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bb83ff9-34e9-4479-b611-35d0360099d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  default_term_info = default_term_info.sort_values(\n"
          ]
        }
      ],
      "source": [
        "lda_display = pyLDAvis.sklearn.prepare(lda_text_model, count_text_vectors, count_text_vectorizer, sort_topics=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "2a89fc15",
      "metadata": {
        "id": "2a89fc15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "b1b83fdf-30d0-4d48-aa93-4edc2e996c6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1031404527615358721100715869\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1031404527615358721100715869_data = {\"mdsDat\": {\"x\": [-0.24352303362204103, 0.13055719395525955, -0.05665667547392695, 0.041427484839751436, 0.1281950303009572], \"y\": [0.006829720679473201, -0.05588474470164696, 0.038523662874466014, -0.11285215230955768, 0.12338351345726539], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [22.896957296534488, 20.4319685428418, 32.00626407252674, 12.368825612932158, 12.295984475164815]}, \"tinfo\": {\"Term\": [\"states\", \"state\", \"said\", \"mrs\", \"united\", \"shall\", \"development\", \"tax\", \"feed\", \"fiscal\", \"college\", \"government\", \"ll\", \"don\", \"000\", \"university\", \"department\", \"didn\", \"sales\", \"president\", \"rhode\", \"got\", \"equipment\", \"little\", \"mother\", \"class\", \"act\", \"program\", \"system\", \"property\", \"hair\", \"baby\", \"clothes\", \"walls\", \"anne\", \"fig\", \"pale\", \"pink\", \"dry\", \"yellow\", \"entrance\", \"hadn\", \"ham\", \"couldn\", \"frames\", \"fingers\", \"flowers\", \"windows\", \"bride\", \"hell\", \"handsome\", \"coat\", \"cloth\", \"sweet\", \"stared\", \"liked\", \"colored\", \"studio\", \"bed\", \"trees\", \"shelter\", \"mother\", \"looked\", \"clay\", \"wasn\", \"guests\", \"didn\", \"woman\", \"sat\", \"pieces\", \"colors\", \"eyes\", \"drill\", \"mrs\", \"ll\", \"don\", \"thought\", \"room\", \"sun\", \"inch\", \"ve\", \"black\", \"little\", \"knew\", \"went\", \"sure\", \"got\", \"door\", \"look\", \"son\", \"know\", \"said\", \"way\", \"come\", \"came\", \"good\", \"place\", \"away\", \"old\", \"water\", \"right\", \"man\", \"let\", \"life\", \"left\", \"house\", \"day\", \"home\", \"systems\", \"marketing\", \"electronic\", \"boats\", \"missiles\", \"components\", \"aircraft\", \"machine\", \"rhode\", \"assessment\", \"shipments\", \"laboratory\", \"bankers\", \"savings\", \"yield\", \"industrial\", \"forests\", \"compared\", \"machines\", \"procurement\", \"missile\", \"conservation\", \"utility\", \"inventories\", \"polaris\", \"manufacturing\", \"machinery\", \"investment\", \"recreation\", \"banks\", \"property\", \"industry\", \"equipment\", \"sales\", \"radiation\", \"planning\", \"development\", \"medical\", \"providence\", \"billion\", \"system\", \"shares\", \"manufacturers\", \"island\", \"1960\", \"production\", \"1959\", \"products\", \"research\", \"co\", \"range\", \"000\", \"program\", \"business\", \"cost\", \"million\", \"available\", \"state\", \"small\", \"company\", \"national\", \"1961\", \"provide\", \"areas\", \"service\", \"use\", \"military\", \"tax\", \"public\", \"khrushchev\", \"player\", \"rayburn\", \"congo\", \"republican\", \"moscow\", \"southern\", \"baseball\", \"railroad\", \"castro\", \"troops\", \"yards\", \"charter\", \"yankees\", \"premier\", \"alexander\", \"democrats\", \"captain\", \"chinese\", \"coach\", \"laos\", \"gen\", \"cuban\", \"opposition\", \"soviet\", \"katanga\", \"republicans\", \"pope\", \"bombs\", \"robinson\", \"berlin\", \"speaker\", \"communist\", \"democratic\", \"eisenhower\", \"league\", \"mayor\", \"cuba\", \"st\", \"police\", \"yesterday\", \"china\", \"west\", \"monday\", \"race\", \"john\", \"east\", \"kennedy\", \"city\", \"mr\", \"meeting\", \"party\", \"president\", \"said\", \"week\", \"war\", \"political\", \"nations\", \"game\", \"committee\", \"leaders\", \"american\", \"world\", \"york\", \"home\", \"county\", \"man\", \"united\", \"people\", \"house\", \"state\", \"day\", \"old\", \"000\", \"government\", \"men\", \"national\", \"states\", \"school\", \"academic\", \"faculty\", \"trustees\", \"campus\", \"recognition\", \"classical\", \"professors\", \"mathematics\", \"musical\", \"tends\", \"feed\", \"stockholders\", \"fulfill\", \"meat\", \"unions\", \"chemical\", \"motors\", \"prosperity\", \"cattle\", \"prestige\", \"designer\", \"curriculum\", \"clerical\", \"catholic\", \"collective\", \"recorded\", \"appearances\", \"creative\", \"membership\", \"trust\", \"music\", \"chamber\", \"students\", \"student\", \"colleges\", \"teachers\", \"college\", \"engineer\", \"interior\", \"university\", \"daily\", \"pool\", \"schools\", \"education\", \"art\", \"general\", \"anti\", \"members\", \"technical\", \"labor\", \"design\", \"administration\", \"level\", \"work\", \"school\", \"president\", \"problem\", \"board\", \"department\", \"american\", \"good\", \"men\", \"aid\", \"world\", \"high\", \"cousin\", \"rehabilitation\", \"coal\", \"vocational\", \"definition\", \"denied\", \"thereof\", \"bonds\", \"payment\", \"rico\", \"puerto\", \"coordination\", \"filing\", \"adopting\", \"recommendation\", \"calendar\", \"hated\", \"proceedings\", \"commodities\", \"sectors\", \"connections\", \"62\", \"vehicles\", \"allocation\", \"treasury\", \"tractor\", \"adjustments\", \"upstairs\", \"shall\", \"assigned\", \"india\", \"exercise\", \"interference\", \"payments\", \"fiscal\", \"authorized\", \"claim\", \"stations\", \"insurance\", \"claims\", \"class\", \"states\", \"income\", \"return\", \"tax\", \"united\", \"junior\", \"hearing\", \"act\", \"countries\", \"cars\", \"state\", \"agreement\", \"department\", \"government\", \"secretary\", \"officer\", \"section\", \"title\", \"federal\", \"use\", \"service\", \"30\", \"board\", \"services\", \"pay\", \"local\", \"day\"], \"Freq\": [328.0, 485.0, 803.0, 307.0, 298.0, 123.0, 199.0, 172.0, 93.0, 107.0, 120.0, 273.0, 167.0, 178.0, 282.0, 122.0, 153.0, 124.0, 117.0, 297.0, 86.0, 147.0, 105.0, 237.0, 97.0, 97.0, 127.0, 230.0, 142.0, 95.0, 35.2660316976795, 35.25985457287086, 32.34282391715049, 32.33880808918395, 34.23407300433103, 31.327619231629452, 26.498517625454497, 25.524771041025016, 23.57323677816412, 25.427138253320578, 21.619428115149056, 30.993044678951435, 19.675700186736574, 51.43981707238505, 20.589733305570036, 17.726312752092976, 23.305040810822835, 16.751973310918498, 17.67796618496797, 15.781789493525485, 15.780666162782103, 15.765038139000257, 14.807347406646533, 14.806857679256789, 14.80652524389838, 14.805562659021431, 15.721341674975074, 14.793031300690537, 34.148748494261206, 27.742455010304496, 57.20416985925254, 90.05985801714505, 78.93387784968824, 75.71076669182489, 53.907238782962956, 29.98283937143006, 108.73073941993053, 50.250850745194825, 34.93419186644635, 48.29752376267051, 27.141746207592945, 83.9918324965762, 31.328311483268095, 234.3324322419555, 134.73682388828402, 142.22532063651946, 113.48998687104911, 84.70739288661422, 47.85107317359335, 58.28164360651536, 69.82209572678218, 54.447334924203055, 159.93873456068224, 71.32903793545289, 100.47914727932279, 70.80739412891499, 101.5476355074319, 56.56434544201607, 89.14937958191945, 57.9427876563148, 112.80221967394888, 300.1915799527002, 143.08214720581634, 108.667855284092, 97.93192846288167, 146.7201649075109, 107.63695959300956, 81.83857826579658, 125.33252753577953, 93.65427756652977, 105.80662989454596, 122.43392673750697, 76.37882747857937, 81.85609009063349, 81.25833894745266, 87.71132897871978, 85.95109916972167, 84.11085690371269, 37.620339176968784, 41.26043043714816, 26.108504126894086, 38.01490066718638, 22.24099597794042, 21.22351437468652, 54.248483592252654, 50.39470006191909, 82.33814930496462, 17.22632723406696, 13.5995027170789, 16.29088859098535, 10.74063215723178, 17.005387252552136, 15.133342494227298, 72.03843499105989, 14.938223060272406, 24.574363297207988, 28.908173871233398, 17.44886776203956, 36.58474259793829, 7.854789008100241, 11.322258118599793, 6.910963131905757, 6.906977941612571, 18.16721140781805, 30.179415379306562, 24.918058009903802, 32.62393120086366, 16.267831354180647, 85.04409531611363, 85.23076408361699, 92.04061867537709, 102.21030740338115, 31.419941862258078, 72.2935473615963, 160.58456695669383, 84.12221117794046, 39.27101304252765, 47.15352590830218, 110.99031567699508, 32.5265688805094, 35.56961213374262, 88.51387155669495, 93.20958887097933, 63.84974612826233, 50.27196273949966, 49.69605754659324, 72.63469421541097, 46.82621040883035, 53.98496787689065, 144.62866634727357, 123.50896845655318, 113.1986105479081, 73.61038906890643, 79.16133829903141, 74.66204969189853, 169.46520342296253, 100.42960965644941, 76.12853270707218, 92.20105914345238, 67.16061893470119, 66.50125650021168, 62.63129522802728, 86.66947068148015, 95.41631280398212, 65.25389352558294, 67.8417383114945, 65.61364145319396, 73.42554374783126, 48.67768498296596, 46.70642783836328, 43.73337493489189, 39.77817876808446, 37.80010747839433, 34.827228410194245, 39.61877024477503, 32.84180904847269, 29.881397928372564, 26.91281765701297, 26.899591011392978, 27.860295497571613, 25.92561583302563, 24.935202646112852, 24.927860722599338, 23.946196773271836, 23.93872466553854, 22.949710429481566, 22.94066110961125, 49.614781943724125, 21.955319680146978, 20.97470862289916, 20.95696065584776, 78.92743956978482, 19.982341472209377, 19.97284168478858, 19.967439518925552, 18.996535964167766, 18.994551077568087, 63.22425972645921, 40.660686563695094, 70.96278176057119, 59.00465760184119, 38.64663320997927, 57.99120476200673, 43.21771150153889, 36.746255661940786, 71.47530467432689, 44.37915026504124, 58.029653582731065, 32.82823725515494, 96.0841853883144, 58.465154170308566, 40.505659296092986, 142.98368478351796, 83.85420121427471, 111.14875577393441, 172.623532000264, 287.8781423603007, 84.13213702614414, 92.01772270153523, 205.406348737347, 470.8902208582257, 140.76265143256003, 113.0113995026159, 71.05038233619995, 67.1651888988563, 73.87620209973903, 83.761719452907, 50.00246714063654, 148.6461501680538, 138.13586962558068, 96.83009236355026, 140.02404620727498, 76.83350051553279, 129.58037547484753, 125.62152536157608, 118.36210204722768, 110.56501449328101, 148.84517946191184, 119.60071243642473, 108.76991140081155, 105.30536803757681, 99.52164947706387, 90.46561781119023, 91.57849254494324, 96.15786407278637, 83.84436994950643, 27.814826569302816, 48.9368470900438, 18.503509985386017, 14.87946847708759, 15.473941152164265, 9.373352607053885, 8.42986417373588, 7.546272419664469, 18.414920463159174, 7.5189597994270905, 84.441554361045, 18.268486568333238, 6.622128289059275, 19.541713824662367, 18.587130254335964, 23.146111999202674, 38.25197181315954, 4.773288678682485, 17.381566736920497, 10.238816773832252, 14.802706325018912, 7.011676741661581, 4.663272913791573, 25.479595882436183, 10.014582060857459, 7.582398158918782, 4.5400150413288305, 12.853649254073673, 19.425628383036713, 29.706978723475125, 46.825010878351016, 21.450400541392497, 52.9943684019599, 54.95528137360975, 16.311008295186504, 25.620730698223657, 83.62014229714096, 24.941675902345906, 28.633459492336502, 67.0124173425636, 33.331261741900036, 43.62737654411692, 49.32037920830968, 46.4182857041601, 34.85619603196495, 67.6689962592213, 32.10381351159186, 51.62302814445676, 31.177936996003, 33.89549304217507, 35.04082063901762, 44.49327955892653, 35.22883442674176, 56.48861252778341, 47.16711951156658, 55.687789661336836, 39.64150536052242, 42.71566054538847, 38.01482404768383, 43.01510978367293, 42.90256178570281, 38.25715440917941, 34.068781601686155, 37.628796504514426, 34.84607073269751, 24.895381739117923, 17.60871047105591, 22.617152720693422, 12.988354717680886, 12.081651178952166, 17.25576125805929, 11.043916669732521, 28.504391307942086, 36.7518717272335, 17.292619041590697, 17.289973715259734, 6.586201822372026, 15.531276371536094, 5.6697498607221855, 16.06995842193472, 20.125736782358167, 5.62662761528911, 6.416436823858529, 14.343171489794212, 4.7615347567452355, 5.547238482984891, 5.532508833757186, 35.56950814402402, 10.223530392476112, 22.866566967658468, 19.499373411737214, 10.913572827235164, 5.430408333634594, 101.1673393785031, 9.141628146127092, 29.60437781154295, 21.94557072459189, 28.494458626329145, 31.902747941397045, 82.24350507900928, 23.619992267391048, 32.82368814475597, 43.573997396850075, 25.757310222259697, 22.21335819721853, 63.525155444168014, 175.30239292056623, 50.03986268624463, 41.16101243435983, 86.65875331991694, 128.3923792638737, 39.9103417174385, 33.81578682770485, 65.0107752835121, 47.420605346201775, 40.20927959281319, 156.29426259716834, 38.83917469224578, 66.04762002987046, 93.49618556474583, 54.83909075025131, 32.98378789632127, 41.664568001741614, 29.989970407909468, 43.23305137556804, 57.37752089386131, 52.70114914664639, 42.224181185310215, 42.52715360132947, 36.829108002785986, 37.096810629375746, 36.7444212874195, 37.176157676027124], \"Total\": [328.0, 485.0, 803.0, 307.0, 298.0, 123.0, 199.0, 172.0, 93.0, 107.0, 120.0, 273.0, 167.0, 178.0, 282.0, 122.0, 153.0, 124.0, 117.0, 297.0, 86.0, 147.0, 105.0, 237.0, 97.0, 97.0, 127.0, 230.0, 142.0, 95.0, 36.02603912499985, 36.025888838190355, 33.103221722997645, 33.103199451516204, 35.050562559486124, 32.128537874832716, 27.257595896582224, 26.283381057698204, 24.334723323645928, 26.284575607309364, 22.386171312703556, 32.13491772930471, 20.437642353730425, 53.48541765786134, 21.413009212119373, 18.48897769781579, 24.31987835813563, 17.514841028502047, 18.48997788651864, 16.54070720566731, 16.540683839194852, 16.54015211825249, 15.566432075823172, 15.56636855315958, 15.566439385894089, 15.56640853615906, 16.541123102771508, 15.566128130021555, 35.96189057796924, 29.21687336390236, 60.42030248595256, 97.50813665440423, 85.71452146351677, 82.76557482881313, 58.488069645836035, 32.15043643449322, 124.7730510913908, 55.495934070275915, 37.89639184076529, 53.44875378566885, 29.186855354435657, 98.42108266493295, 34.108659255171254, 307.99715835781416, 167.83422712513698, 178.1854227837812, 139.82171036116083, 103.42674442190592, 54.56223811623199, 68.76954856434932, 84.83647160041036, 64.26201397041542, 237.75277971425635, 90.51973633420369, 137.70593095628732, 91.77444009129964, 147.79376856176168, 70.06214294099414, 129.86657516906672, 73.99592681862173, 191.48072080434144, 803.8548070648294, 274.85427260577245, 186.0737233498349, 163.1589979967047, 306.4340359076893, 190.1554441273065, 123.89985251249686, 254.84946828941247, 162.71698521260237, 213.57338284403215, 283.01536045192034, 121.9563692552673, 161.53017716157908, 163.20991301290178, 234.12184367687414, 302.34647433345043, 268.5137641979603, 38.38900181276883, 42.21975114655716, 26.87023951148848, 39.325305112537464, 23.031355908186352, 22.069023878838752, 56.67664066614093, 52.83541185825132, 86.46800449904785, 18.221477632163275, 14.390064081926617, 17.262361508112328, 11.511442662430959, 18.23745719845576, 16.292903446551136, 78.46760127905368, 16.284197226960217, 26.802268957257585, 31.64526338081065, 19.147274411366567, 40.18955772227331, 8.631750433563738, 12.458169098970643, 7.671836647717205, 7.671950307157877, 20.188446423100267, 33.582287155475136, 27.758165731678787, 36.446484492775724, 18.17983889287438, 95.5995810902008, 96.93212392160395, 105.65758026062852, 117.78573708942231, 35.55944348942251, 85.01192732215918, 199.0011368393309, 101.02292341395626, 45.14381488359435, 54.901189630749755, 142.6626279152401, 37.275769525790764, 41.99097586369721, 120.33277045687886, 129.77818451581413, 84.83256378608142, 63.727084038071986, 62.84418723668013, 102.98876739202464, 59.708950181379954, 72.90815716855997, 282.9442741244362, 230.32157269786694, 209.32374748162178, 115.94033775080969, 128.99304695412943, 119.7157257981743, 485.5254739281196, 211.37539248235058, 138.53740854960475, 215.73422314818586, 114.91801537520546, 112.9357554678229, 99.90679935398613, 203.5790903421851, 253.4486972460467, 123.30539886857125, 172.80964183116558, 200.80538207395298, 74.18132611605128, 49.44169052826694, 47.46260119923946, 44.49359036010497, 40.53551399617137, 38.55638985076477, 35.58752782843549, 40.524089011304056, 33.60786999510346, 30.63965223281023, 27.670894341231325, 27.67080987821845, 28.65913593377031, 26.681481371686967, 25.691806203590637, 25.691678325478694, 24.702282074756567, 24.7021542729878, 23.712487033002045, 23.71193932275297, 51.34436129166911, 22.722416271833243, 21.733411082028482, 21.732251919217536, 81.93116365784137, 20.743599793201977, 20.742911377657396, 20.74332961345866, 19.75425783489286, 19.754312772549586, 66.10674015267465, 42.436983762163024, 74.99667222533029, 62.130383241294645, 40.45277924173405, 61.20732427285944, 45.3792727728093, 38.47958552212629, 78.03996648950977, 47.29725623534732, 63.02723087036464, 34.528652937106514, 108.34119862739153, 64.00922906655562, 43.340703141696395, 171.40817645781527, 96.50766365165029, 132.04188079153843, 217.90548917781655, 392.85663935368353, 99.38191347480667, 110.41190710132184, 297.089385911943, 803.8548070648294, 190.9527989971512, 148.12895827305644, 84.33186741272114, 80.65436811910897, 91.54281280787272, 111.05863796939241, 55.26520309710712, 262.8761488078902, 256.0899824588553, 148.4697207814734, 268.5137641979603, 105.8449818383527, 283.01536045192034, 298.72403397416906, 265.6177234105347, 234.12184367687414, 485.5254739281196, 302.34647433345043, 254.84946828941247, 282.9442741244362, 273.1049196397213, 193.49518722056055, 215.73422314818586, 328.0876630034327, 171.6826664515605, 28.587671191002926, 50.752351040054734, 19.380805810594023, 15.693304333758915, 16.633414863075238, 10.165631588135202, 9.24571212382064, 8.322226888959067, 20.348539793129664, 8.322341294361474, 93.52912134200916, 20.35067352827831, 7.401195317063848, 22.202972880525156, 21.263556998272605, 26.864176614307805, 44.466850734734706, 5.559156794388782, 20.429848324794353, 12.080566726948922, 17.616166085442238, 8.344571664079332, 5.563614525856902, 30.74006234011115, 12.097121988775989, 9.30906225992752, 5.575810965371236, 15.790102910241046, 24.236359627179493, 37.140658075135605, 59.64261324812856, 27.081082977874402, 68.97438698866311, 71.68275492289169, 20.467141713564462, 33.3476013502525, 120.99975166695657, 32.580289308120776, 39.89608051957491, 122.31078776847805, 52.498527601506225, 75.23212830270086, 89.4581258414869, 84.56146294600381, 57.4932583527358, 198.00621277778873, 57.797206402033446, 140.21994582812476, 57.243567658301565, 68.34216300022536, 74.72871037779436, 131.40907157119446, 82.98496450235842, 256.97786239275575, 171.6826664515605, 297.089385911943, 117.36282478725465, 173.02514764709477, 153.03062002567157, 262.8761488078902, 306.4340359076893, 193.49518722056055, 99.64739691842246, 256.0899824588553, 217.960932031602, 25.719900356958107, 18.379206160058768, 23.884995096222177, 13.795801363596565, 12.877393873437684, 18.39587213444213, 11.965555537317105, 31.301788527830052, 40.52555344944815, 19.305747619464757, 19.305381735641966, 7.373665018594341, 17.516110794478635, 6.456504867903861, 18.386543136831968, 23.075914689335114, 6.459370956327406, 7.37405791546939, 16.593451639249736, 5.538818995171569, 6.462219526241353, 6.457204216744038, 41.58244844081571, 11.963052970316319, 26.870254060738787, 23.09135146214558, 12.931560935207846, 6.471692815484675, 123.04949327572979, 11.129093826135726, 36.08726596770417, 26.774612595552796, 35.19197255344369, 39.791548185353264, 107.51555928474946, 29.573704296915555, 42.546659941506675, 57.808559354593925, 33.291642037189185, 28.658975142612572, 97.1696828583257, 328.0876630034327, 79.94285226747925, 64.56516799991905, 172.80964183116558, 298.72403397416906, 62.790765491912666, 50.551680739664874, 127.86759220361668, 82.87435176840468, 65.84647973719706, 485.5254739281196, 64.87874739797834, 153.03062002567157, 273.1049196397213, 119.84296064796641, 52.25627453052494, 81.49566812100716, 44.58064300425603, 112.63804601931176, 253.4486972460467, 203.5790903421851, 114.3879313715759, 173.02514764709477, 93.38657624530407, 103.89058589990492, 128.42114372832094, 302.34647433345043], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.6963, -6.6965, -6.7828, -6.7829, -6.726, -6.8147, -6.9821, -7.0195, -7.0991, -7.0234, -7.1856, -6.8254, -7.2798, -6.3188, -7.2344, -7.3841, -7.1105, -7.4407, -7.3869, -7.5003, -7.5004, -7.5014, -7.5641, -7.5641, -7.5641, -7.5642, -7.5042, -7.565, -6.7285, -6.9362, -6.2126, -5.7587, -5.8906, -5.9323, -6.2719, -6.8586, -5.5703, -6.3422, -6.7057, -6.3818, -6.9581, -5.8285, -6.8147, -4.8025, -5.3559, -5.3018, -5.5275, -5.82, -6.3911, -6.1939, -6.0132, -6.262, -5.1844, -5.9919, -5.6492, -5.9992, -5.6387, -6.2238, -5.7689, -6.1997, -5.5336, -4.5548, -5.2958, -5.5709, -5.6749, -5.2707, -5.5804, -5.8544, -5.4282, -5.7196, -5.5976, -5.4516, -5.9235, -5.8542, -5.8616, -5.7851, -5.8054, -5.8271, -6.5177, -6.4254, -6.883, -6.5073, -7.0434, -7.0902, -6.1517, -6.2254, -5.7345, -7.2989, -7.5353, -7.3547, -7.7713, -7.3118, -7.4284, -5.8681, -7.4414, -6.9436, -6.7812, -7.286, -6.5457, -8.0842, -7.7185, -8.2122, -8.2128, -7.2457, -6.7381, -6.9297, -6.6602, -7.3561, -5.7021, -5.6999, -5.6231, -5.5183, -6.6978, -5.8646, -5.0665, -5.713, -6.4748, -6.2919, -5.4358, -6.6632, -6.5738, -5.6621, -5.6104, -5.9888, -6.2278, -6.2394, -5.8598, -6.2988, -6.1566, -5.1711, -5.329, -5.4161, -5.8465, -5.7738, -5.8323, -5.0126, -5.5358, -5.8129, -5.6213, -5.9382, -5.9481, -6.008, -5.6832, -5.587, -5.967, -5.9281, -5.9615, -6.2979, -6.7089, -6.7502, -6.816, -6.9108, -6.9618, -7.0437, -6.9148, -7.1024, -7.1969, -7.3015, -7.302, -7.2669, -7.3389, -7.3778, -7.3781, -7.4183, -7.4186, -7.4608, -7.4612, -6.6898, -7.5051, -7.5508, -7.5517, -6.2256, -7.5993, -7.5997, -7.6, -7.6499, -7.65, -6.4474, -6.8889, -6.332, -6.5165, -6.9397, -6.5338, -6.8279, -6.9901, -6.3248, -6.8014, -6.5332, -7.1028, -6.0289, -6.5257, -6.8927, -5.6314, -6.165, -5.8833, -5.443, -4.9316, -6.1617, -6.0721, -5.2691, -4.4395, -5.647, -5.8666, -6.3307, -6.387, -6.2917, -6.1661, -6.6821, -5.5926, -5.6659, -6.0212, -5.6523, -6.2525, -5.7298, -5.7608, -5.8204, -5.8885, -5.5912, -5.81, -5.9049, -5.9373, -5.9937, -6.0892, -6.0769, -6.0281, -6.1652, -6.3178, -5.7528, -6.7254, -6.9434, -6.9042, -7.4055, -7.5116, -7.6223, -6.7302, -7.6259, -5.2073, -6.7382, -7.753, -6.6708, -6.7209, -6.5015, -5.9992, -8.0803, -6.788, -7.3172, -6.9486, -7.6958, -8.1037, -6.4055, -7.3393, -7.6175, -8.1304, -7.0897, -6.6768, -6.252, -5.797, -6.5776, -5.6732, -5.6369, -6.8515, -6.4, -5.2171, -6.4268, -6.2888, -5.4385, -6.1369, -5.8677, -5.745, -5.8057, -6.0921, -5.4287, -6.1744, -5.6994, -6.2037, -6.1201, -6.0869, -5.848, -6.0815, -5.6093, -5.7897, -5.6236, -5.9635, -5.8888, -6.0054, -5.8818, -5.8844, -5.999, -6.115, -6.0156, -6.0924, -6.4228, -6.7691, -6.5188, -7.0734, -7.1458, -6.7893, -7.2356, -6.2874, -6.0333, -6.7872, -6.7873, -7.7525, -6.8946, -7.9023, -6.8605, -6.6355, -7.91, -7.7786, -6.9742, -8.0769, -7.9242, -7.9268, -6.066, -7.3128, -6.5078, -6.6671, -7.2475, -7.9454, -5.0207, -7.4246, -6.2495, -6.5489, -6.2878, -6.1748, -5.2278, -6.4754, -6.1463, -5.863, -6.3887, -6.5368, -5.486, -4.471, -5.7246, -5.92, -5.1755, -4.7824, -5.9508, -6.1165, -5.4629, -5.7784, -5.9434, -4.5857, -5.978, -5.4471, -5.0995, -5.6331, -6.1414, -5.9078, -6.2366, -5.8709, -5.5878, -5.6728, -5.8945, -5.8873, -6.0312, -6.0239, -6.0335, -6.0218], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4528, 1.4527, 1.4509, 1.4508, 1.4506, 1.4489, 1.4459, 1.4449, 1.4424, 1.441, 1.4393, 1.438, 1.4362, 1.4352, 1.435, 1.432, 1.4315, 1.4296, 1.4293, 1.4272, 1.4271, 1.4262, 1.4242, 1.4241, 1.4241, 1.4241, 1.4233, 1.4232, 1.4224, 1.4224, 1.4195, 1.3947, 1.3918, 1.3851, 1.3926, 1.4044, 1.3365, 1.3749, 1.3928, 1.3728, 1.4015, 1.3156, 1.3891, 1.2008, 1.2545, 1.2488, 1.2655, 1.2745, 1.3429, 1.3087, 1.2794, 1.3084, 1.0777, 1.2359, 1.159, 1.2148, 1.0989, 1.2602, 1.098, 1.2296, 0.945, 0.4892, 0.8213, 0.9363, 0.9637, 0.7377, 0.9051, 1.0594, 0.7645, 0.9218, 0.7718, 0.6362, 1.0062, 0.7944, 0.7768, 0.4924, 0.2164, 0.3134, 1.5678, 1.5651, 1.5593, 1.5542, 1.5532, 1.549, 1.5443, 1.5408, 1.5391, 1.5319, 1.5316, 1.5301, 1.5188, 1.5181, 1.5142, 1.5026, 1.5018, 1.5013, 1.4976, 1.4952, 1.4941, 1.4937, 1.4925, 1.4836, 1.483, 1.4826, 1.4812, 1.4801, 1.4773, 1.4769, 1.4711, 1.4594, 1.4501, 1.4462, 1.4643, 1.426, 1.3736, 1.405, 1.4487, 1.4359, 1.337, 1.4518, 1.4221, 1.281, 1.2571, 1.3039, 1.3509, 1.3533, 1.2389, 1.345, 1.2876, 0.917, 0.9649, 0.9733, 1.1338, 1.0998, 1.1159, 0.5355, 0.8439, 0.9894, 0.738, 1.0509, 1.0585, 1.1211, 0.7341, 0.6112, 0.9517, 0.6531, 0.4695, 1.129, 1.1237, 1.1232, 1.122, 1.1204, 1.1194, 1.1176, 1.1166, 1.1162, 1.1142, 1.1115, 1.111, 1.111, 1.1105, 1.1093, 1.1091, 1.1082, 1.1078, 1.1065, 1.1062, 1.105, 1.1049, 1.1037, 1.1029, 1.1019, 1.1018, 1.1014, 1.1011, 1.1001, 1.1, 1.0947, 1.0965, 1.084, 1.0876, 1.0936, 1.0853, 1.0904, 1.0931, 1.0514, 1.0756, 1.0566, 1.0887, 1.0192, 1.0486, 1.0716, 0.9579, 0.9987, 0.967, 0.9063, 0.8283, 0.9727, 0.957, 0.7702, 0.6044, 0.8343, 0.8686, 0.9679, 0.9562, 0.9248, 0.8572, 1.0392, 0.5691, 0.5219, 0.7118, 0.4882, 0.8189, 0.358, 0.273, 0.3309, 0.389, -0.0431, 0.2118, 0.2878, 0.1509, 0.1298, 0.379, 0.2824, -0.0881, 0.4226, 2.0626, 2.0536, 2.0437, 2.0367, 2.0177, 2.0088, 1.9976, 1.9921, 1.9901, 1.9885, 1.9878, 1.9821, 1.9788, 1.9623, 1.9555, 1.941, 1.9394, 1.9376, 1.9284, 1.9246, 1.916, 1.916, 1.9135, 1.9023, 1.9011, 1.8848, 1.8845, 1.8842, 1.8687, 1.8667, 1.848, 1.8569, 1.8264, 1.8243, 1.863, 1.8264, 1.7205, 1.8228, 1.7583, 1.4883, 1.6357, 1.5451, 1.4946, 1.4902, 1.5896, 1.0163, 1.502, 1.0907, 1.4824, 1.3887, 1.3326, 1.007, 1.2332, 0.575, 0.798, 0.4157, 1.0046, 0.6911, 0.6973, 0.2799, 0.1239, 0.4691, 1.0167, 0.1722, 0.2566, 2.0633, 2.0531, 2.0414, 2.0356, 2.0321, 2.0319, 2.0157, 2.0023, 1.9982, 1.9858, 1.9856, 1.983, 1.9756, 1.966, 1.9612, 1.9591, 1.9579, 1.9568, 1.9502, 1.9447, 1.9432, 1.9413, 1.9397, 1.9388, 1.9346, 1.9268, 1.9262, 1.9205, 1.9001, 1.8992, 1.8979, 1.897, 1.8848, 1.8749, 1.8279, 1.8711, 1.8364, 1.8132, 1.8393, 1.8411, 1.6709, 1.4691, 1.6274, 1.6457, 1.4057, 1.2515, 1.6427, 1.6938, 1.4195, 1.5376, 1.6027, 0.9624, 1.5828, 1.2556, 1.024, 1.3141, 1.6358, 1.425, 1.6995, 1.1383, 0.6104, 0.7445, 1.0993, 0.6926, 1.1654, 1.0661, 0.8446, -0.0]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 2, 3, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 4, 1, 2, 3, 4, 5, 2, 5, 2, 3, 4, 5, 5, 2, 3, 5, 1, 2, 3, 4, 5, 2, 3, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 3, 5, 2, 4, 5, 1, 2, 4, 5, 1, 3, 4, 5, 1, 2, 2, 5, 3, 1, 5, 3, 4, 2, 3, 1, 3, 4, 1, 2, 3, 4, 5, 2, 5, 3, 2, 5, 1, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 5, 4, 3, 2, 3, 5, 3, 3, 4, 1, 3, 4, 3, 4, 3, 2, 4, 3, 4, 3, 1, 2, 3, 5, 2, 3, 4, 5, 2, 3, 4, 5, 1, 3, 4, 5, 4, 1, 2, 3, 4, 1, 1, 1, 2, 3, 4, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 1, 2, 3, 4, 5, 2, 3, 4, 2, 4, 5, 2, 3, 5, 2, 3, 4, 5, 2, 5, 2, 3, 5, 2, 5, 1, 2, 3, 4, 5, 1, 5, 2, 3, 4, 5, 2, 3, 4, 5, 5, 2, 3, 4, 3, 5, 3, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 3, 4, 3, 2, 5, 2, 3, 4, 5, 1, 2, 4, 2, 4, 1, 2, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 3, 4, 1, 3, 1, 1, 2, 3, 5, 1, 2, 3, 4, 5, 3, 5, 2, 1, 2, 4, 1, 1, 2, 4, 1, 4, 5, 1, 3, 4, 1, 4, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 5, 1, 2, 5, 1, 2, 5, 1, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 2, 3, 4, 5, 1, 3, 1, 3, 1, 1, 1, 5, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 4, 5, 2, 3, 4, 5, 2, 4, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 3, 2, 3, 4, 5, 3, 1, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 1, 3, 4, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 3, 2, 3, 5, 1, 2, 4, 1, 2, 3, 4, 5, 2, 4, 2, 3, 2, 4, 3, 4, 3, 4, 5, 2, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 2, 4, 2, 1, 3, 4, 5, 3, 1, 3, 2, 4, 1, 2, 3, 4, 5, 1, 3, 1, 4, 2, 4, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 1, 3, 4, 1, 2, 3, 4, 5, 2, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 1, 2, 3, 4, 5, 1, 2, 4, 5, 3, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 4, 5, 3, 3, 1, 2, 3, 4, 5, 3, 4, 2, 3, 4, 5, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 4, 2, 3, 4, 5, 1, 2, 4, 5, 4, 1, 2, 3, 4, 5, 2, 3, 4, 2, 3, 4, 5, 4, 5, 3, 5, 1, 2, 3, 1, 2, 3, 4, 5, 3, 1, 4, 4, 5, 3, 4, 1, 2, 5, 5, 3, 3, 1, 2, 3, 4, 5, 1, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 3, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 3, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 4, 5, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 3, 2, 1, 2, 3, 4, 5, 1, 3, 4, 5, 3, 3, 4, 3, 4, 5, 1, 3, 1, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 3, 5, 1, 3, 4, 5, 1, 1, 2, 3, 4, 5, 2, 2, 4, 5, 3, 4, 5, 2, 4, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 2, 5, 3, 5, 1, 3, 3, 2, 3, 4, 5, 4, 2, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 5, 2, 3, 5, 5, 1, 1, 2, 3, 4, 5, 1, 3, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 2, 3, 5, 1, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 3, 1, 1, 3, 4, 2, 5, 1, 2, 3, 4, 5], \"Freq\": [0.0035342648409990777, 0.5124684019448662, 0.37109780830490313, 0.021205589045994466, 0.09542515070697509, 0.784595761044533, 0.20399489787157857, 0.7166073431137224, 0.19263638255745227, 0.09246546362757709, 0.008701855812032746, 0.5830243394061939, 0.21754639530081862, 0.052211134872196474, 0.14793154880455667, 0.017484361995351, 0.17484361995351, 0.3933981448953975, 0.0437109049883775, 0.36717160190237097, 0.9291947100637655, 0.9794431946877898, 0.01564117979804605, 0.2189765171726447, 0.08602648888925328, 0.1798735676775296, 0.5083383434364966, 0.07733018504188235, 0.8506320354607059, 0.281563514281084, 0.3120028131222823, 0.334832287253181, 0.0684884223926961, 0.9292953575899545, 0.15413367860908495, 0.23120051791362742, 0.6011213465754313, 0.01003538507702978, 0.37130924785010183, 0.20070770154059558, 0.3412030926190125, 0.07024769553920845, 0.9527734771383517, 0.03528790656067969, 0.9730777290328771, 0.08359070234674039, 0.835907023467404, 0.03804072771664042, 0.15216291086656167, 0.5668068429779423, 0.16357512918155379, 0.08368960097660892, 0.9700272268753701, 0.39794310887646644, 0.5536599775672577, 0.03460374859795361, 0.8967305439608104, 0.0600559725543906, 0.6305877118211013, 0.1801679176631718, 0.0600559725543906, 0.0600559725543906, 0.2087201237817648, 0.0521800309454412, 0.1391467491878432, 0.608767027696814, 0.9329649517552183, 0.08985457536997175, 0.8086911783297458, 0.13525529165506628, 0.03381382291376657, 0.8115317499303977, 0.10859057916849094, 0.6264841105874477, 0.10859057916849094, 0.15870930801548677, 0.6618248394745205, 0.29055724659856996, 0.024213103883214165, 0.03228413851095222, 0.9715235662110069, 0.9555709325556461, 0.880095808014626, 0.05500598800091412, 0.9870672228767965, 0.9454452881525889, 0.027807214357429083, 0.9530041846640815, 0.03025410110044703, 0.8560834531293224, 0.1275017908916012, 0.8403097983337436, 0.10892904793215195, 0.031122585123471987, 0.1329286540873886, 0.03467704019671007, 0.34099089526764903, 0.24851878807642216, 0.24851878807642216, 0.9662989235876281, 0.02542891904177969, 0.9618179614138386, 0.06389411257512725, 0.9264646323393452, 0.9735003530276858, 0.1098776430133392, 0.5398336374133622, 0.1289867983200069, 0.14809595362667458, 0.07165933240000383, 0.04333522694388211, 0.04333522694388211, 0.8667045388776422, 0.6006410998060879, 0.09193486221521753, 0.30032054990304397, 0.006128990814347836, 0.9558216473080496, 0.9715751806410011, 0.12149472579140405, 0.2733631330306591, 0.6074736289570203, 0.9791233846928176, 0.16265419193622627, 0.8132709596811313, 0.09789597887384864, 0.04894798943692432, 0.8321158204277135, 0.18463072559118351, 0.7754490474829708, 0.9770008441533778, 0.1116728810665355, 0.8561587548434388, 0.9557279880019954, 0.02896145418187865, 0.9699530870797974, 0.06424803731573571, 0.08719376492849845, 0.7939221754015912, 0.055069746270630604, 0.09401443040415432, 0.04700721520207716, 0.07051082280311574, 0.7756190508342732, 0.1046792491731272, 0.034893083057709065, 0.06978616611541813, 0.7676478272695995, 0.15436913612108974, 0.12349530889687178, 0.07203893018984188, 0.6586416474499829, 0.885336038589509, 0.9182561730187146, 0.048329272264142874, 0.024164636132071437, 0.8986963379224956, 0.9636119521118188, 0.9666732823702411, 0.050243723778207385, 0.787151672525249, 0.13398326340855302, 0.033495815852138254, 0.9699754915419414, 0.041867289315800076, 0.9629476542634018, 0.9673429775983489, 0.16532857995940273, 0.8266428997970137, 0.18181855497152982, 0.02479343931429952, 0.09917375725719808, 0.6942163008003865, 0.09771760160699494, 0.09771760160699494, 0.04885880080349747, 0.7817408128559595, 0.9672861933612693, 0.9250739647050291, 0.03426199869277886, 0.5857893206934461, 0.05374213951316019, 0.29558176732238106, 0.048367925561844174, 0.016122641853948058, 0.05402551399607108, 0.7563571959449951, 0.18908929898624877, 0.06026473706257865, 0.06026473706257865, 0.8437063188761011, 0.026667849927939812, 0.9467086724418633, 0.026667849927939812, 0.5485882895866889, 0.2021114751108854, 0.15158360633316403, 0.09383747058719678, 0.9327568512900263, 0.0746205481032021, 0.9515599835902211, 0.988906483920265, 0.9284735647923438, 0.9268108550604942, 0.94932438378309, 0.07762613232457266, 0.6382593102242641, 0.02587537744152422, 0.043125629069207035, 0.21562814534603517, 0.9535309292383167, 0.01869668488702582, 0.15686397205650504, 0.26546210655716235, 0.012066459388961925, 0.5671235912812105, 0.2456422548185365, 0.7274789854241274, 0.009447779031482173, 0.018895558062964345, 0.9720099865486707, 0.12666161907677323, 0.06333080953838661, 0.8233005239990261, 0.9615488186255148, 0.025987805908797696, 0.9662542120396855, 0.11983838598986152, 0.8388687019290306, 0.03809630653227346, 0.05714445979841019, 0.19048153266136728, 0.6285890577825121, 0.07619261306454692, 0.28444188141963495, 0.09922391212312846, 0.39689564849251385, 0.09591644838569084, 0.12237615828519177, 0.9318655713989231, 0.9496159032346987, 0.04828555440176434, 0.971570154019323, 0.05436002124235932, 0.9241203611201084, 0.26138559716538967, 0.058811759362212675, 0.24831631730712017, 0.43128623532289295, 0.3345434421872313, 0.18734432762484954, 0.46836081906212385, 0.11353208128826471, 0.8514906096619853, 0.010050193841931444, 0.8090406042754812, 0.055276066130622935, 0.12562742302414304, 0.873586075250835, 0.10418916493817298, 0.01602910229818046, 0.7969226538374559, 0.01683639409515752, 0.14030328412631266, 0.01683639409515752, 0.02806065682526253, 0.8135634681914456, 0.1284573897144388, 0.05709217320641724, 0.9088601157871679, 0.05863613650239793, 0.9862450326969331, 0.03108561420395239, 0.07253309980922225, 0.8703971977106669, 0.020723742802634927, 0.011825717828918636, 0.34294581703864047, 0.08278002480243046, 0.5439830201302573, 0.023651435657837273, 0.9640870350822458, 0.02472018038672425, 0.9676132581134452, 0.061386809094463486, 0.15346702273615873, 0.7673351136807937, 0.9827495596585373, 0.10410989890991248, 0.8707373363374499, 0.018929072529074997, 0.07469762607628525, 0.07469762607628525, 0.8216738868391378, 0.8534756753893022, 0.12192509648418604, 0.020320849414031006, 0.01970352071396221, 0.9654725149841483, 0.3284858119223443, 0.2219498729205029, 0.07102395933456092, 0.38175378142326494, 0.06415114259503969, 0.010691857099173281, 0.021383714198346563, 0.8981159963305557, 0.9648742846864272, 0.05709029885305455, 0.9134447816488728, 0.9735530159748337, 0.23252448451473687, 0.762680309208337, 0.9457284144805727, 0.9211384381396406, 0.06140922920930937, 0.9807122292794972, 0.9457931726056641, 0.07646695338815279, 0.10923850484021828, 0.8083649358176153, 0.010923850484021828, 0.9682068903592462, 0.0202013863296753, 0.2222152496264283, 0.2676683688681977, 0.3434235676044801, 0.15151039747256476, 0.4797117251175145, 0.08158362672066573, 0.21864411961138414, 0.14032383795954503, 0.08158362672066573, 0.6901508838471435, 0.3112445162447902, 0.20504940033257157, 0.3661596434510207, 0.08787831442824497, 0.3405284684094492, 0.9331133050440931, 0.06220755366960621, 0.9646827249142217, 0.031118797577878117, 0.9715195133875308, 0.9785864560033001, 0.967311881150062, 0.9288830198121041, 0.2769443032388642, 0.05934520783689947, 0.6725790221515273, 0.9673105146627559, 0.2110469962265095, 0.29363060344557845, 0.2569267780148811, 0.1605792362593007, 0.07799562904023177, 0.3128331251506029, 0.08938089290017226, 0.5213885419176715, 0.04469044645008613, 0.0335178348375646, 0.3758726593724171, 0.06834048352225766, 0.4741121044356625, 0.06834048352225766, 0.017085120880564415, 0.843396549938495, 0.043623959479577326, 0.014541319826525775, 0.08724791895915465, 0.012508935716405505, 0.2626876500445156, 0.08756255001483854, 0.6254467858202752, 0.05542121150961877, 0.08313181726442816, 0.027710605754809384, 0.8313181726442815, 0.9175761566094903, 0.07646467971745752, 0.8769022751296122, 0.06189898412679615, 0.030949492063398074, 0.02063299470893205, 0.12015027662293465, 0.030037569155733662, 0.060075138311467324, 0.7809767980490752, 0.08524671344989546, 0.08524671344989546, 0.028415571149965152, 0.7956359921990243, 0.1253255942660022, 0.025065118853200445, 0.7268884467428128, 0.1253255942660022, 0.9124281865520281, 0.9006358792457583, 0.07205087033966066, 0.07479259362041484, 0.7396156480241022, 0.13296461088073747, 0.016620576360092183, 0.033241152720184367, 0.12251457564025975, 0.011668054822881881, 0.8342659198360545, 0.023336109645763763, 0.005834027411440941, 0.01592590872504649, 0.27074044832579036, 0.07962954362523245, 0.6370363490018596, 0.9641528085474506, 0.007573354711440027, 0.840642372969843, 0.05301348298008019, 0.09845361124872035, 0.9840751550571746, 0.7843593328405666, 0.1546624036587033, 0.011047314547050234, 0.044189258188200936, 0.590137740892805, 0.010444915768014248, 0.28723518362039185, 0.06266949460808549, 0.04700212095606412, 0.1463225563985592, 0.33654187971668614, 0.49749669175510125, 0.01463225563985592, 0.9268720268939398, 0.9738167686217329, 0.01947633537243466, 0.03618913688755974, 0.05428370533133961, 0.9047284221889935, 0.01633791399771122, 0.9475990118672508, 0.01633791399771122, 0.4962933838068827, 0.44114967449500686, 0.049016630499445206, 0.01838123643729195, 0.623173684688203, 0.008199653745897408, 0.20499134364743518, 0.1065954986966663, 0.05739757622128185, 0.08435262992491924, 0.40971277392103633, 0.03615112711067967, 0.4217631496245962, 0.048201502814239565, 0.5076450818101634, 0.04333555576428224, 0.2662041282663052, 0.14857904833468197, 0.03714476208367049, 0.963613409294549, 0.6729679467566955, 0.008412099334458693, 0.20189038402700862, 0.050472596006752156, 0.06729679467566954, 0.8043651304768972, 0.17874780677264382, 0.005958260225754794, 0.011916520451509588, 0.015573759444403208, 0.4672127833320962, 0.1868851133328385, 0.03893439861100802, 0.28811454972145933, 0.6853187579955459, 0.12320337222391836, 0.10780295069592856, 0.046201264583969386, 0.038501053819974485, 0.921664131714546, 0.023333269157330278, 0.046666538314660555, 0.011666634578665139, 0.9463350098252615, 0.03785340039301046, 0.8933280768254317, 0.059555205121695445, 0.029777602560847723, 0.03160030580141701, 0.9164088682410932, 0.03160030580141701, 0.4310720089721978, 0.021200262736337596, 0.45933902595398124, 0.08126767382262745, 0.003533377122722933, 0.857327062768345, 0.1428878437947242, 0.8915990672468894, 0.04953328151371608, 0.971109466222976, 0.9612811699009842, 0.947569173602206, 0.04407298481870726, 0.04503901371140834, 0.9007802742281668, 0.04503901371140834, 0.8314944485995289, 0.05939246061425207, 0.09898743435708678, 0.030186579178318, 0.08049754447551467, 0.845224216992904, 0.030186579178318, 0.04992157113354103, 0.0713165301907729, 0.5134790173735648, 0.37084595699201905, 0.04126032190406043, 0.1237809657121813, 0.7839461161771483, 0.17054687754266512, 0.15504261594787738, 0.46512784784363215, 0.196387313533978, 0.010336174396525158, 0.5271464234042356, 0.4298270836988382, 0.03243977990179911, 0.0077523558332225845, 0.6124361108245842, 0.16279947249767426, 0.031009423332890338, 0.18605653999734204, 0.9206371529561364, 0.07464625564509214, 0.9552194880623697, 0.03124549426959098, 0.9061193338181385, 0.01562274713479549, 0.03124549426959098, 0.9855694515768121, 0.922999896090568, 0.07178888080704417, 0.13493197518737654, 0.8545691761867181, 0.11454560135227117, 0.12981834819924065, 0.7330918486545355, 0.010181831231312994, 0.012727289039141242, 0.7597472692528925, 0.23701517374128697, 0.20119842754167935, 0.7880271745382441, 0.04914357541948208, 0.8845843575506775, 0.02317666583926995, 0.4264506514425671, 0.4264506514425671, 0.11124799602849576, 0.01390599950356197, 0.148783014235244, 0.8307051628134458, 0.012398584519603668, 0.012398584519603668, 0.019136457946611958, 0.21050103741273152, 0.13395520562628369, 0.6315031122381946, 0.4904856221165325, 0.00784776995386452, 0.42770346248561636, 0.051010504700119384, 0.02354330986159356, 0.9663057504606776, 0.9538625526127229, 0.1449119068771927, 0.8332434645438579, 0.018113988359649086, 0.0770040897421421, 0.33689289262187166, 0.12513164583098088, 0.10588062339544538, 0.35614391505740717, 0.07402736655385152, 0.9130041874975021, 0.1759167541658157, 0.804190876186586, 0.2409477770467996, 0.1468275516378935, 0.4442474639300367, 0.12423869753975604, 0.04141289917991868, 0.8980564858907932, 0.01870951012272486, 0.01870951012272486, 0.03741902024544972, 0.989218241858758, 0.5679563921803651, 0.08414168773042446, 0.16828337546084893, 0.0736239767641214, 0.10517710966303058, 0.023526110547062974, 0.846939979694267, 0.05881527636765743, 0.05881527636765743, 0.9910664355618177, 0.9124146689882817, 0.9302865219297196, 0.021142875498402717, 0.021142875498402717, 0.059289568147826516, 0.8419118676991365, 0.04743165451826121, 0.04743165451826121, 0.1462141275033568, 0.026584386818792143, 0.5848565100134272, 0.23925948136912928, 0.9641653665390163, 0.9730728856465548, 0.013463961318313795, 0.06731980659156898, 0.690028017563582, 0.18849545845639315, 0.03702589362536294, 0.08277757348661745, 0.8277757348661745, 0.2726587406021189, 0.23857639802685407, 0.3408234257526487, 0.1533705415886919, 0.8136632596027116, 0.8878548264764065, 0.052226754498612145, 0.04715170474025311, 0.7544272758440498, 0.011787926185063278, 0.10609133566556951, 0.08251548329544295, 0.015912370641915665, 0.7956185320957833, 0.06364948256766266, 0.12729896513532532, 0.8652659625199459, 0.5383777062110534, 0.21708778476252155, 0.09117686960025906, 0.1519614493337651, 0.01046029688201743, 0.8891252349714817, 0.01046029688201743, 0.08368237505613944, 0.8994169772377755, 0.008854591673448495, 0.5932576421210491, 0.07969132506103646, 0.15938265012207292, 0.15938265012207292, 0.8639057222027758, 0.0886057150977206, 0.0443028575488603, 0.3286764493976232, 0.41333553484852614, 0.14939838608982872, 0.1095588164658744, 0.05179902752991311, 0.8805834680085229, 0.9459929587657175, 0.04614599798857159, 0.11248769967926628, 0.8717796725143137, 0.9819128675755999, 0.054863545525532936, 0.7406578645946946, 0.10972709105106587, 0.054863545525532936, 0.0411476591441497, 0.9902533534287862, 0.0601199457977757, 0.9017991869666355, 0.10877520505709391, 0.8702016404567513, 0.10742220559687028, 0.8593776447749623, 0.05487497704741405, 0.9054371212823319, 0.027437488523707025, 0.9793676529466844, 0.9867890167564682, 0.9641848068416471, 0.03883918704235076, 0.7088151635229014, 0.05825878056352614, 0.15535674816940304, 0.04854898380293845, 0.15488227336468074, 0.13939404602821268, 0.0619529093458723, 0.635017320795191, 0.9483276557041738, 0.03469491423307953, 0.0517980458312717, 0.8805667791316188, 0.49631652871935555, 0.018728925612051153, 0.2809338841807673, 0.10300909086628134, 0.09832685946326855, 0.9618152865536395, 0.8218377217140452, 0.16436754434280904, 0.009668679078988768, 0.37320172419620246, 0.017416080462489446, 0.5859267069880378, 0.0037320172419620244, 0.019904091957130797, 0.8659792137868283, 0.050939953752166374, 0.008489992292027728, 0.07640993062824956, 0.9235707754728874, 0.026387736442082498, 0.052775472884164995, 0.054832205450476616, 0.9321474926581025, 0.174740995232995, 0.04077289888769883, 0.48927478665238594, 0.27376089253169217, 0.017474099523299497, 0.011178414376486324, 0.10060572938837692, 0.25710353065918545, 0.5477423044478299, 0.08942731501189059, 0.05840977193948172, 0.33377012536846695, 0.14185230328159845, 0.45893392238164205, 0.1349764994093536, 0.2699529988187072, 0.0736235451323747, 0.5153648159266229, 0.902719515542703, 0.009824191652680577, 0.42735233689160507, 0.2161322163589727, 0.08841772487412519, 0.2603410787960353, 0.41761890807043167, 0.11778994843012176, 0.06424906278006641, 0.39620255381040953, 0.016253622398252322, 0.04876086719475696, 0.07314130079213545, 0.0406340559956308, 0.8208079311117422, 0.8852935947349819, 0.026827078628332786, 0.10730831451333114, 0.9433915034313546, 0.04965218439112393, 0.9728935132112078, 0.3453571352024591, 0.47309196603076586, 0.10881115218707614, 0.05204011626338424, 0.014192758980922976, 0.7838269279627942, 0.16217108854402637, 0.04054277213600659, 0.013514257378668865, 0.9834906253879754, 0.9642240689991611, 0.024410735924029398, 0.9661384095953529, 0.02356435145354519, 0.02356435145354519, 0.07688368242452447, 0.9097902420235394, 0.9636114995952522, 0.00823849666967667, 0.3480764842938393, 0.3068840009454559, 0.014417369171934171, 0.32130137011739013, 0.12191863489722712, 0.2926047237533451, 0.04876745395889085, 0.5333940276753687, 0.05189542921487104, 0.19028324045452713, 0.7611329618181085, 0.04913842279521847, 0.8844916103139324, 0.11160285355390578, 0.013950356694238223, 0.05580142677695289, 0.7672696181831022, 0.05580142677695289, 0.014498135375445436, 0.11598508300356349, 0.10148694762811804, 0.768401174898608, 0.014498135375445436, 0.963630767696837, 0.8797293083496193, 0.091638469619752, 0.0183276939239504, 0.7736358830341795, 0.07627396029914446, 0.021792560085469845, 0.141651640555554, 0.96361588438399, 0.021028632682852193, 0.7780594092655312, 0.08411453073140877, 0.05607635382093919, 0.06308589804855659, 0.9898668422100143, 0.3934965623413291, 0.10416085473741064, 0.5034441312308181, 0.08996149283694387, 0.7796662712535135, 0.14993582139490644, 0.4367302916762641, 0.5415455616785675, 0.9612679553793516, 0.9193054150886838, 0.8081720621791846, 0.014303930304056365, 0.10012751212839455, 0.05006375606419727, 0.02860786060811273, 0.06729378039059677, 0.11215630065099463, 0.1570188209113925, 0.6729378039059678, 0.12991877088346257, 0.8228188822619296, 0.11164762317537671, 0.8559651110112214, 0.9583503221324903, 0.03422679721901751, 0.9757545118362274, 0.026924671016248517, 0.10769868406499407, 0.8077401304874555, 0.053849342032497034, 0.9803513943478106, 0.047028820252474096, 0.8935475847970078, 0.047028820252474096, 0.11046985259597003, 0.4217939826391583, 0.03682328419865668, 0.42848912522073224, 0.02452768112064405, 0.08175893706881349, 0.34338753568901664, 0.5477848783610504, 0.772595384632072, 0.24857101529640108, 0.37482930878028736, 0.07891143342742891, 0.07102029008468602, 0.2248975852681724, 0.8829547835330696, 0.0802686166848245, 0.8251168239257772, 0.02357476639787935, 0.1414485983872761, 0.011787383198939676, 0.09619443178516049, 0.048097215892580245, 0.8657498860664444, 0.9423156841257172, 0.9666739327377712, 0.03375437225976538, 0.16202098684687383, 0.7628488130706976, 0.03375437225976538, 0.013501748903906152, 0.9232652116403784, 0.06839001567706507, 0.5776901524888856, 0.30113635608463185, 0.030728199600472638, 0.09218459880141791, 0.5202757033546538, 0.09459558242811886, 0.23648895607029716, 0.10551045732367104, 0.04729779121405943, 0.11521171784618991, 0.05236896265735905, 0.7384023734687626, 0.06284275518883085, 0.03142137759441543, 0.7261851345512743, 0.24690294574743327, 0.02178555403653823, 0.08307089190468454, 0.8860895136499685, 0.027690297301561514, 0.9706054409706464, 0.9009669057319357, 0.07207735245855486, 0.018019338114638715, 0.2840711620848858, 0.22570037535511475, 0.1673295886253437, 0.21791760379114528, 0.1050674161135879, 0.10933656885426443, 0.17962436311772015, 0.5388730893531604, 0.14838534344507315, 0.023429264754485236, 0.9744586381020762, 0.9757574902516138, 0.951128158715557, 0.01586615794777364, 0.920237160970871, 0.06346463179109456, 0.9206462217865278, 0.06137641478576852, 0.06735380081113372, 0.20879678251451453, 0.6533318678679971, 0.06061842073002035, 0.013470760162226744], \"Term\": [\"000\", \"000\", \"000\", \"000\", \"000\", \"1959\", \"1959\", \"1960\", \"1960\", \"1960\", \"1961\", \"1961\", \"1961\", \"1961\", \"1961\", \"30\", \"30\", \"30\", \"30\", \"30\", \"62\", \"academic\", \"act\", \"act\", \"act\", \"act\", \"act\", \"adjustments\", \"adjustments\", \"administration\", \"administration\", \"administration\", \"administration\", \"adopting\", \"agreement\", \"agreement\", \"agreement\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aircraft\", \"aircraft\", \"alexander\", \"allocation\", \"allocation\", \"american\", \"american\", \"american\", \"american\", \"american\", \"anne\", \"anti\", \"anti\", \"anti\", \"appearances\", \"areas\", \"areas\", \"areas\", \"areas\", \"areas\", \"art\", \"art\", \"art\", \"art\", \"assessment\", \"assigned\", \"assigned\", \"authorized\", \"authorized\", \"authorized\", \"available\", \"available\", \"available\", \"available\", \"away\", \"away\", \"away\", \"away\", \"baby\", \"bankers\", \"banks\", \"banks\", \"baseball\", \"bed\", \"bed\", \"berlin\", \"berlin\", \"billion\", \"billion\", \"black\", \"black\", \"black\", \"board\", \"board\", \"board\", \"board\", \"board\", \"boats\", \"boats\", \"bombs\", \"bonds\", \"bonds\", \"bride\", \"business\", \"business\", \"business\", \"business\", \"business\", \"calendar\", \"calendar\", \"calendar\", \"came\", \"came\", \"came\", \"came\", \"campus\", \"captain\", \"cars\", \"cars\", \"cars\", \"castro\", \"catholic\", \"catholic\", \"cattle\", \"cattle\", \"cattle\", \"chamber\", \"chamber\", \"charter\", \"chemical\", \"chemical\", \"china\", \"china\", \"chinese\", \"city\", \"city\", \"city\", \"city\", \"claim\", \"claim\", \"claim\", \"claim\", \"claims\", \"claims\", \"claims\", \"claims\", \"class\", \"class\", \"class\", \"class\", \"classical\", \"clay\", \"clay\", \"clay\", \"clerical\", \"cloth\", \"clothes\", \"co\", \"co\", \"co\", \"co\", \"coach\", \"coal\", \"coal\", \"coat\", \"collective\", \"collective\", \"college\", \"college\", \"college\", \"college\", \"colleges\", \"colleges\", \"colleges\", \"colleges\", \"colored\", \"colors\", \"colors\", \"come\", \"come\", \"come\", \"come\", \"come\", \"committee\", \"committee\", \"committee\", \"commodities\", \"commodities\", \"commodities\", \"communist\", \"communist\", \"communist\", \"company\", \"company\", \"company\", \"company\", \"compared\", \"compared\", \"components\", \"congo\", \"connections\", \"conservation\", \"coordination\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"couldn\", \"couldn\", \"countries\", \"countries\", \"countries\", \"countries\", \"county\", \"county\", \"county\", \"county\", \"cousin\", \"creative\", \"creative\", \"creative\", \"cuba\", \"cuba\", \"cuban\", \"curriculum\", \"curriculum\", \"daily\", \"daily\", \"daily\", \"daily\", \"daily\", \"day\", \"day\", \"day\", \"day\", \"day\", \"definition\", \"democratic\", \"democratic\", \"democrats\", \"denied\", \"denied\", \"department\", \"department\", \"department\", \"department\", \"design\", \"design\", \"design\", \"designer\", \"designer\", \"development\", \"development\", \"development\", \"development\", \"didn\", \"didn\", \"didn\", \"don\", \"don\", \"don\", \"don\", \"don\", \"door\", \"door\", \"door\", \"drill\", \"drill\", \"dry\", \"east\", \"east\", \"east\", \"east\", \"education\", \"education\", \"education\", \"education\", \"education\", \"eisenhower\", \"eisenhower\", \"electronic\", \"engineer\", \"engineer\", \"engineer\", \"entrance\", \"equipment\", \"equipment\", \"equipment\", \"exercise\", \"exercise\", \"exercise\", \"eyes\", \"eyes\", \"eyes\", \"faculty\", \"faculty\", \"federal\", \"federal\", \"federal\", \"federal\", \"feed\", \"feed\", \"feed\", \"feed\", \"fig\", \"filing\", \"filing\", \"fingers\", \"fiscal\", \"fiscal\", \"flowers\", \"forests\", \"forests\", \"frames\", \"fulfill\", \"game\", \"game\", \"game\", \"game\", \"gen\", \"general\", \"general\", \"general\", \"general\", \"general\", \"good\", \"good\", \"good\", \"good\", \"good\", \"got\", \"got\", \"government\", \"government\", \"government\", \"government\", \"guests\", \"guests\", \"hadn\", \"hadn\", \"hair\", \"ham\", \"handsome\", \"hated\", \"hearing\", \"hearing\", \"hearing\", \"hell\", \"high\", \"high\", \"high\", \"high\", \"high\", \"home\", \"home\", \"home\", \"home\", \"home\", \"house\", \"house\", \"house\", \"house\", \"house\", \"inch\", \"inch\", \"inch\", \"inch\", \"income\", \"income\", \"income\", \"income\", \"india\", \"india\", \"india\", \"india\", \"industrial\", \"industrial\", \"industry\", \"industry\", \"industry\", \"industry\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"interference\", \"interference\", \"interference\", \"interference\", \"interior\", \"interior\", \"interior\", \"interior\", \"inventories\", \"investment\", \"investment\", \"island\", \"island\", \"island\", \"island\", \"island\", \"john\", \"john\", \"john\", \"john\", \"john\", \"junior\", \"junior\", \"junior\", \"junior\", \"katanga\", \"kennedy\", \"kennedy\", \"kennedy\", \"kennedy\", \"khrushchev\", \"knew\", \"knew\", \"knew\", \"knew\", \"know\", \"know\", \"know\", \"know\", \"know\", \"labor\", \"labor\", \"labor\", \"labor\", \"laboratory\", \"laos\", \"laos\", \"leaders\", \"leaders\", \"leaders\", \"league\", \"league\", \"league\", \"left\", \"left\", \"left\", \"left\", \"let\", \"let\", \"let\", \"let\", \"let\", \"level\", \"level\", \"level\", \"level\", \"level\", \"life\", \"life\", \"life\", \"life\", \"life\", \"liked\", \"little\", \"little\", \"little\", \"little\", \"little\", \"ll\", \"ll\", \"ll\", \"ll\", \"local\", \"local\", \"local\", \"local\", \"local\", \"look\", \"look\", \"look\", \"look\", \"look\", \"looked\", \"looked\", \"looked\", \"looked\", \"machine\", \"machine\", \"machinery\", \"machinery\", \"machinery\", \"machines\", \"machines\", \"machines\", \"man\", \"man\", \"man\", \"man\", \"man\", \"manufacturers\", \"manufacturers\", \"manufacturing\", \"manufacturing\", \"marketing\", \"mathematics\", \"mayor\", \"mayor\", \"meat\", \"meat\", \"meat\", \"medical\", \"medical\", \"medical\", \"meeting\", \"meeting\", \"meeting\", \"meeting\", \"members\", \"members\", \"members\", \"members\", \"membership\", \"membership\", \"membership\", \"men\", \"men\", \"men\", \"men\", \"men\", \"military\", \"military\", \"military\", \"million\", \"million\", \"million\", \"million\", \"million\", \"missile\", \"missile\", \"missiles\", \"monday\", \"monday\", \"monday\", \"monday\", \"moscow\", \"mother\", \"mother\", \"motors\", \"motors\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mrs\", \"mrs\", \"music\", \"music\", \"musical\", \"musical\", \"national\", \"national\", \"national\", \"national\", \"national\", \"nations\", \"nations\", \"nations\", \"nations\", \"officer\", \"officer\", \"officer\", \"officer\", \"old\", \"old\", \"old\", \"old\", \"old\", \"opposition\", \"pale\", \"party\", \"party\", \"party\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"payment\", \"payment\", \"payments\", \"payments\", \"people\", \"people\", \"people\", \"people\", \"people\", \"pieces\", \"pieces\", \"pieces\", \"pieces\", \"pink\", \"place\", \"place\", \"place\", \"place\", \"place\", \"planning\", \"planning\", \"planning\", \"planning\", \"player\", \"polaris\", \"police\", \"police\", \"police\", \"political\", \"political\", \"political\", \"political\", \"pool\", \"pool\", \"pool\", \"pool\", \"pope\", \"premier\", \"president\", \"president\", \"president\", \"president\", \"president\", \"prestige\", \"prestige\", \"problem\", \"problem\", \"problem\", \"problem\", \"proceedings\", \"procurement\", \"procurement\", \"production\", \"production\", \"production\", \"production\", \"production\", \"products\", \"products\", \"products\", \"products\", \"professors\", \"program\", \"program\", \"program\", \"program\", \"property\", \"property\", \"property\", \"property\", \"prosperity\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"providence\", \"providence\", \"providence\", \"public\", \"public\", \"public\", \"public\", \"puerto\", \"puerto\", \"race\", \"race\", \"radiation\", \"radiation\", \"railroad\", \"range\", \"range\", \"range\", \"range\", \"range\", \"rayburn\", \"recognition\", \"recognition\", \"recommendation\", \"recommendation\", \"recorded\", \"recorded\", \"recreation\", \"recreation\", \"recreation\", \"rehabilitation\", \"republican\", \"republicans\", \"research\", \"research\", \"research\", \"research\", \"research\", \"return\", \"return\", \"return\", \"return\", \"rhode\", \"rhode\", \"rico\", \"rico\", \"right\", \"right\", \"right\", \"right\", \"right\", \"robinson\", \"room\", \"room\", \"room\", \"said\", \"said\", \"said\", \"said\", \"said\", \"sales\", \"sales\", \"sales\", \"sales\", \"sat\", \"sat\", \"sat\", \"savings\", \"savings\", \"school\", \"school\", \"school\", \"school\", \"school\", \"schools\", \"schools\", \"schools\", \"schools\", \"schools\", \"secretary\", \"secretary\", \"secretary\", \"secretary\", \"section\", \"section\", \"section\", \"section\", \"sectors\", \"service\", \"service\", \"service\", \"service\", \"service\", \"services\", \"services\", \"services\", \"services\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shares\", \"shares\", \"shares\", \"shelter\", \"shelter\", \"shipments\", \"small\", \"small\", \"small\", \"small\", \"small\", \"son\", \"son\", \"son\", \"son\", \"southern\", \"soviet\", \"soviet\", \"speaker\", \"speaker\", \"speaker\", \"st\", \"st\", \"stared\", \"state\", \"state\", \"state\", \"state\", \"state\", \"states\", \"states\", \"states\", \"states\", \"stations\", \"stations\", \"stations\", \"stockholders\", \"stockholders\", \"student\", \"student\", \"student\", \"student\", \"student\", \"students\", \"students\", \"students\", \"students\", \"students\", \"studio\", \"sun\", \"sun\", \"sun\", \"sure\", \"sure\", \"sure\", \"sure\", \"sweet\", \"system\", \"system\", \"system\", \"system\", \"system\", \"systems\", \"tax\", \"tax\", \"tax\", \"teachers\", \"teachers\", \"teachers\", \"technical\", \"technical\", \"tends\", \"thereof\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"title\", \"title\", \"title\", \"title\", \"tractor\", \"tractor\", \"treasury\", \"treasury\", \"trees\", \"trees\", \"troops\", \"trust\", \"trust\", \"trust\", \"trust\", \"trustees\", \"unions\", \"unions\", \"unions\", \"united\", \"united\", \"united\", \"united\", \"university\", \"university\", \"university\", \"university\", \"upstairs\", \"use\", \"use\", \"use\", \"use\", \"use\", \"utility\", \"utility\", \"ve\", \"ve\", \"ve\", \"ve\", \"vehicles\", \"vehicles\", \"vehicles\", \"vocational\", \"walls\", \"war\", \"war\", \"war\", \"war\", \"war\", \"wasn\", \"wasn\", \"water\", \"water\", \"water\", \"water\", \"way\", \"way\", \"way\", \"way\", \"way\", \"week\", \"week\", \"week\", \"week\", \"week\", \"went\", \"went\", \"went\", \"west\", \"west\", \"west\", \"windows\", \"woman\", \"woman\", \"woman\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"yankees\", \"yards\", \"yellow\", \"yesterday\", \"yesterday\", \"yesterday\", \"yield\", \"yield\", \"york\", \"york\", \"york\", \"york\", \"york\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1031404527615358721100715869\", ldavis_el1031404527615358721100715869_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1031404527615358721100715869\", ldavis_el1031404527615358721100715869_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1031404527615358721100715869\", ldavis_el1031404527615358721100715869_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "pyLDAvis.display(lda_display)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3d14c87",
      "metadata": {
        "id": "a3d14c87"
      },
      "source": [
        "Q: What conclusions do you draw from the visualization above? Please address the principal component scatterplot and the salient terms graph.\n",
        "\n",
        "First, there is no overlap for any topics within the Intertopic Distance Map. With the exception topics 2 and 4, the topics generally far from one another (in two dimensions). This translates to topics 2 and 4 being more similar to one another than other topics. When looking at the individual word distributions within 2 and 4 however, no word overlap is observed. \n",
        "\n",
        "Topic 3 is the most pronounced topic, as the red bars, representing the word distributions are decrease very quickly.\n",
        "\n",
        "Topics 1, 2 and 5 are moderatly pronounced, as the red bars, representing the word distributions are decrease, but not at the same rate as Topic 3. \n",
        "\n",
        "Lastly, Topic 4 is the least pronounced, as when looking at the red bars, the bars are not decreaseing quickly. \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}